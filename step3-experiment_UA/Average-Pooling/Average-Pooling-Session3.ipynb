{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf849cbb-094b-463e-8679-10042219e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082277c9-ccb7-4aee-9818-552360c56ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=5, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(5, 4) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.conv1d(x) \n",
    "        x = x.mean(dim=2) \n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d8709f-5709-4344-8bea-46712316c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# 训练函数\n",
    "def train(model, train_data, train_labels, criterion, optimizer, num_epochs, batch_size):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        total_correct_per_class = np.zeros(len(np.unique(train_labels)))  \n",
    "        total_samples_per_class = np.zeros(len(np.unique(train_labels)))  \n",
    "\n",
    "        indices = np.arange(len(train_data))\n",
    "        np.random.shuffle(indices)  # 随机打乱索引\n",
    "\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            inputs = torch.tensor(train_data[batch_indices], dtype=torch.float32)\n",
    "            labels = torch.tensor(train_labels[batch_indices], dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 计算每个类的正确样本数和总样本数\n",
    "            for label in range(len(np.unique(train_labels))):\n",
    "                total_correct_per_class[label] += ((predicted == labels) & (labels == label)).sum().item()\n",
    "                total_samples_per_class[label] += (labels == label).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / (len(train_data) / batch_size)\n",
    "\n",
    "        # 计算每个类的准确率，并取平均得到 UA\n",
    "        class_accuracies = total_correct_per_class / total_samples_per_class\n",
    "        epoch_ua = np.mean(class_accuracies)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, UA: {epoch_ua:.4f}')\n",
    "\n",
    "        print('########################')\n",
    "\n",
    "        test(model, wav2vec_last3, label_last3)\n",
    "\n",
    "\n",
    "# 测试函数\n",
    "def test(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(test_data, dtype=torch.float32)\n",
    "        labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # 计算每个类的准确率并取平均得到 UA\n",
    "        total_correct_per_class = np.zeros(len(np.unique(test_labels)))  # 用于记录每个类的正确样本数\n",
    "        total_samples_per_class = np.zeros(len(np.unique(test_labels)))  # 用于记录每个类的总样本数\n",
    "\n",
    "        for label in range(len(np.unique(test_labels))):\n",
    "            total_correct_per_class[label] += ((predicted == labels) & (labels == label)).sum().item()\n",
    "            total_samples_per_class[label] += (labels == label).sum().item()\n",
    "\n",
    "        class_accuracies = total_correct_per_class / total_samples_per_class\n",
    "        ua = np.mean(class_accuracies)\n",
    "\n",
    "        print(f'Unweighted Accuracy (UA): {ua:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5264ef-4062-4726-9f10-7c8537d28780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec_last1 (1085, 256, 768)\n",
      "label_last1 (1085,)\n",
      "wav2vec_last2 (1023, 256, 768)\n",
      "label_last2 (1023,)\n",
      "wav2vec_last3 (1151, 256, 768)\n",
      "label_last3 (1151,)\n",
      "wav2vec_last4 (1031, 256, 768)\n",
      "label_last4 (1031,)\n",
      "wav2vec_last5 (1241, 256, 768)\n",
      "label_last5 (1241,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#读取数据集\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session1_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last1 = pickle.load(f)\n",
    "    print('wav2vec_last1',wav2vec_last1.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session1_label.pkl', 'rb') as f:\n",
    "    label_last1 = pickle.load(f)\n",
    "    print('label_last1',label_last1.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session2_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last2 = pickle.load(f)\n",
    "    print('wav2vec_last2',wav2vec_last2.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session2_label.pkl', 'rb') as f:\n",
    "    label_last2 = pickle.load(f)\n",
    "    print('label_last2',label_last2.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session3_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last3 = pickle.load(f)\n",
    "    print('wav2vec_last3',wav2vec_last3.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session3_label.pkl', 'rb') as f:\n",
    "    label_last3 = pickle.load(f)\n",
    "    print('label_last3',label_last3.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session4_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last4 = pickle.load(f)\n",
    "    print('wav2vec_last4',wav2vec_last4.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session4_label.pkl', 'rb') as f:\n",
    "    label_last4 = pickle.load(f)\n",
    "    print('label_last4',label_last4.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session5_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last5 = pickle.load(f)\n",
    "    print('wav2vec_last5',wav2vec_last5.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session3_pt_特征/data_Session5_label.pkl', 'rb') as f:\n",
    "    label_last5 = pickle.load(f)\n",
    "    print('label_last5',label_last5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf32e3b-cb71-4de1-a997-25d596db5ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4380, 256, 768) (4380,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wav2vec_last = np.concatenate((wav2vec_last1, wav2vec_last2, wav2vec_last4, wav2vec_last5),axis=0)\n",
    "label_last = np.concatenate((label_last1,label_last2,label_last4,label_last5))\n",
    "print(wav2vec_last.shape,label_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92f7c0d-e316-4b00-a510-c4ad0a6a74d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.1747, UA: 0.4768\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.4229\n",
      "Epoch [2/15], Loss: 0.9066, UA: 0.4977\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.4253\n",
      "Epoch [3/15], Loss: 0.8085, UA: 0.4988\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.4217\n",
      "Epoch [4/15], Loss: 0.7237, UA: 0.4988\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.4819\n",
      "Epoch [5/15], Loss: 0.5852, UA: 0.7252\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.6762\n",
      "Epoch [6/15], Loss: 0.3731, UA: 0.9794\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7080\n",
      "Epoch [7/15], Loss: 0.2102, UA: 0.9907\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7011\n",
      "Epoch [8/15], Loss: 0.1401, UA: 0.9909\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.6997\n",
      "Epoch [9/15], Loss: 0.1064, UA: 0.9909\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7041\n",
      "Epoch [10/15], Loss: 0.0890, UA: 0.9909\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7058\n",
      "Epoch [11/15], Loss: 0.0749, UA: 0.9911\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7059\n",
      "Epoch [12/15], Loss: 0.0686, UA: 0.9909\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7067\n",
      "Epoch [13/15], Loss: 0.0631, UA: 0.9907\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7066\n",
      "Epoch [14/15], Loss: 0.0605, UA: 0.9910\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7067\n",
      "Epoch [15/15], Loss: 0.0587, UA: 0.9909\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.7075\n",
      "Unweighted Accuracy (UA): 0.7075\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 256\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = CustomModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "train(model, wav2vec_last, label_last, criterion, optimizer, num_epochs, batch_size)\n",
    "\n",
    "# 测试模型\n",
    "test(model, wav2vec_last3, label_last3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a3707-d6ef-4fcd-b83d-7a5ea53741e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NeuralCDEenv]",
   "language": "python",
   "name": "neuralcdeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
