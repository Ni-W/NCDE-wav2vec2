{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90f9353-f483-4d0f-8f46-2882bf7148b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768cd882-977b-41f0-9023-fa4d4b01bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=5, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(5, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.conv1d(x)  \n",
    "        x = x.mean(dim=2) \n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba435fd-b335-4e6f-9bf0-e8fed9f1cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# 训练函数\n",
    "def train(model, train_data, train_labels, criterion, optimizer, num_epochs, batch_size):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        total_correct_per_class = np.zeros(len(np.unique(train_labels))) \n",
    "        total_samples_per_class = np.zeros(len(np.unique(train_labels))) \n",
    "\n",
    "        indices = np.arange(len(train_data))\n",
    "        np.random.shuffle(indices)  # 随机打乱索引\n",
    "\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            inputs = torch.tensor(train_data[batch_indices], dtype=torch.float32)\n",
    "            labels = torch.tensor(train_labels[batch_indices], dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # 计算每个类的正确样本数和总样本数\n",
    "            for label in range(len(np.unique(train_labels))):\n",
    "                total_correct_per_class[label] += ((predicted == labels) & (labels == label)).sum().item()\n",
    "                total_samples_per_class[label] += (labels == label).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / (len(train_data) / batch_size)\n",
    "\n",
    "        # 计算每个类的准确率，并取平均得到 UA\n",
    "        class_accuracies = total_correct_per_class / total_samples_per_class\n",
    "        epoch_ua = np.mean(class_accuracies)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, UA: {epoch_ua:.4f}')\n",
    "\n",
    "        print('########################')\n",
    "\n",
    "        test(model, wav2vec_last5, label_last5)\n",
    "\n",
    "\n",
    "# 测试函数\n",
    "def test(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(test_data, dtype=torch.float32)\n",
    "        labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # 计算每个类的准确率并取平均得到 UA\n",
    "        total_correct_per_class = np.zeros(len(np.unique(test_labels)))  # 用于记录每个类的正确样本数\n",
    "        total_samples_per_class = np.zeros(len(np.unique(test_labels)))  # 用于记录每个类的总样本数\n",
    "\n",
    "        for label in range(len(np.unique(test_labels))):\n",
    "            total_correct_per_class[label] += ((predicted == labels) & (labels == label)).sum().item()\n",
    "            total_samples_per_class[label] += (labels == label).sum().item()\n",
    "\n",
    "        class_accuracies = total_correct_per_class / total_samples_per_class\n",
    "        ua = np.mean(class_accuracies)\n",
    "\n",
    "        print(f'Unweighted Accuracy (UA): {ua:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f18cce4-7d48-4a64-8318-5dda85d95fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec_last1 (1085, 256, 768)\n",
      "label_last1 (1085,)\n",
      "wav2vec_last2 (1023, 256, 768)\n",
      "label_last2 (1023,)\n",
      "wav2vec_last3 (1151, 256, 768)\n",
      "label_last3 (1151,)\n",
      "wav2vec_last4 (1031, 256, 768)\n",
      "label_last4 (1031,)\n",
      "wav2vec_last5 (1241, 256, 768)\n",
      "label_last5 (1241,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#读取数据集\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session1_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last1 = pickle.load(f)\n",
    "    print('wav2vec_last1',wav2vec_last1.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session1_label.pkl', 'rb') as f:\n",
    "    label_last1 = pickle.load(f)\n",
    "    print('label_last1',label_last1.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session2_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last2 = pickle.load(f)\n",
    "    print('wav2vec_last2',wav2vec_last2.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session2_label.pkl', 'rb') as f:\n",
    "    label_last2 = pickle.load(f)\n",
    "    print('label_last2',label_last2.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session3_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last3 = pickle.load(f)\n",
    "    print('wav2vec_last3',wav2vec_last3.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session3_label.pkl', 'rb') as f:\n",
    "    label_last3 = pickle.load(f)\n",
    "    print('label_last3',label_last3.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session4_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last4 = pickle.load(f)\n",
    "    print('wav2vec_last4',wav2vec_last4.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session4_label.pkl', 'rb') as f:\n",
    "    label_last4 = pickle.load(f)\n",
    "    print('label_last4',label_last4.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session5_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last5 = pickle.load(f)\n",
    "    print('wav2vec_last5',wav2vec_last5.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session5_label.pkl', 'rb') as f:\n",
    "    label_last5 = pickle.load(f)\n",
    "    print('label_last5',label_last5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50524db-b21a-4940-a6cb-323cdfb81f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4290, 256, 768) (4290,)\n"
     ]
    }
   ],
   "source": [
    "wav2vec_last = np.concatenate((wav2vec_last1, wav2vec_last2, wav2vec_last3, wav2vec_last4),axis=0)\n",
    "label_last = np.concatenate((label_last1,label_last2,label_last3,label_last4))\n",
    "print(wav2vec_last.shape,label_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44625fac-4aea-482d-b6f3-45a7f3c3d99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.1193, UA: 0.3813\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.4062\n",
      "Epoch [2/15], Loss: 0.8047, UA: 0.6777\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.4823\n",
      "Epoch [3/15], Loss: 0.6452, UA: 0.7348\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.4934\n",
      "Epoch [4/15], Loss: 0.5488, UA: 0.7399\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5041\n",
      "Epoch [5/15], Loss: 0.4905, UA: 0.7420\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5080\n",
      "Epoch [6/15], Loss: 0.4537, UA: 0.7421\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5111\n",
      "Epoch [7/15], Loss: 0.4313, UA: 0.7421\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5121\n",
      "Epoch [8/15], Loss: 0.4124, UA: 0.7422\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5121\n",
      "Epoch [9/15], Loss: 0.3993, UA: 0.7422\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5115\n",
      "Epoch [10/15], Loss: 0.3865, UA: 0.7422\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5132\n",
      "Epoch [11/15], Loss: 0.3762, UA: 0.7422\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5135\n",
      "Epoch [12/15], Loss: 0.3669, UA: 0.7422\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5133\n",
      "Epoch [13/15], Loss: 0.3581, UA: 0.7427\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5136\n",
      "Epoch [14/15], Loss: 0.3500, UA: 0.7427\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5148\n",
      "Epoch [15/15], Loss: 0.3424, UA: 0.7429\n",
      "########################\n",
      "Unweighted Accuracy (UA): 0.5188\n",
      "Unweighted Accuracy (UA): 0.5188\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 256\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = CustomModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "train(model, wav2vec_last, label_last, criterion, optimizer, num_epochs, batch_size)\n",
    "\n",
    "# 测试模型\n",
    "test(model, wav2vec_last5, label_last5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b934ae5d-b65a-43ca-b0de-cfd3f840c611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NeuralCDEenv]",
   "language": "python",
   "name": "neuralcdeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
