{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48427a9a-4ea6-4ad5-ac54-b3baa0ba6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26a01fc-3c25-4914-aa97-93f2929ac6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=5, kernel_size=1)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(5, 4) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.conv1d(x)  \n",
    "        x = self.global_avg_pool(x).squeeze(-1) \n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548216cf-1446-4b4e-a11e-f7f2b3a21d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=5, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(5, 4)  # 最终分类成4类\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入 x 的形状是 (batch_size, 256, 768)\n",
    "        x = x.permute(0, 2, 1)  # 变换形状为 (batch_size, 768, 256)\n",
    "        x = self.conv1d(x)  # 经过一维卷积，输出形状为 (batch_size, 5, 256)\n",
    "        x = x.mean(dim=2)  # 在时间维度上求平均，输出形状为 (batch_size, 5)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)  # 经过全连接层，形状为 (batch_size, 4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5069918-bcd6-40c3-881a-31cb710bfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(model, train_data, train_labels, criterion, optimizer, num_epochs, batch_size):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        indices = np.arange(len(train_data))\n",
    "        np.random.shuffle(indices)  # 随机打乱索引\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            inputs = torch.tensor(train_data[batch_indices], dtype=torch.float32)\n",
    "            labels = torch.tensor(train_labels[batch_indices], dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 统计准确率\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / (len(train_data) / batch_size)\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "        print('########################')\n",
    "\n",
    "        test(model, wav2vec_last5, label_last5)\n",
    "\n",
    "\n",
    "        print('########################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70703ce8-b4dc-4046-a684-44200fab13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试函数\n",
    "def test(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(test_data, dtype=torch.float32)\n",
    "        labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        accuracy = (predicted == labels).sum().item() / len(labels)\n",
    "        print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddb19d9-2035-4b7e-8ee3-2dd710951910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec_last1 (1085, 256, 768)\n",
      "label_last1 (1085,)\n",
      "wav2vec_last2 (1023, 256, 768)\n",
      "label_last2 (1023,)\n",
      "wav2vec_last3 (1151, 256, 768)\n",
      "label_last3 (1151,)\n",
      "wav2vec_last4 (1031, 256, 768)\n",
      "label_last4 (1031,)\n",
      "wav2vec_last5 (1241, 256, 768)\n",
      "label_last5 (1241,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#读取数据集\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session1_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last1 = pickle.load(f)\n",
    "    print('wav2vec_last1',wav2vec_last1.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session1_label.pkl', 'rb') as f:\n",
    "    label_last1 = pickle.load(f)\n",
    "    print('label_last1',label_last1.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session2_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last2 = pickle.load(f)\n",
    "    print('wav2vec_last2',wav2vec_last2.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session2_label.pkl', 'rb') as f:\n",
    "    label_last2 = pickle.load(f)\n",
    "    print('label_last2',label_last2.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session3_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last3 = pickle.load(f)\n",
    "    print('wav2vec_last3',wav2vec_last3.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session3_label.pkl', 'rb') as f:\n",
    "    label_last3 = pickle.load(f)\n",
    "    print('label_last3',label_last3.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session4_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last4 = pickle.load(f)\n",
    "    print('wav2vec_last4',wav2vec_last4.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session4_label.pkl', 'rb') as f:\n",
    "    label_last4 = pickle.load(f)\n",
    "    print('label_last4',label_last4.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session5_w2v2.pkl', 'rb') as f:\n",
    "    wav2vec_last5 = pickle.load(f)\n",
    "    print('wav2vec_last5',wav2vec_last5.shape)\n",
    "\n",
    "with open('/home/ni/step1-提取数据特征/整合-按条提取语音_Session5_pt_特征/data_Session5_label.pkl', 'rb') as f:\n",
    "    label_last5 = pickle.load(f)\n",
    "    print('label_last5',label_last5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9877718-3075-48da-bff1-1c495837e859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4290, 256, 768) (4290,)\n"
     ]
    }
   ],
   "source": [
    "wav2vec_last = np.concatenate((wav2vec_last1, wav2vec_last2, wav2vec_last3, wav2vec_last4),axis=0)\n",
    "label_last = np.concatenate((label_last1,label_last2,label_last3,label_last4))\n",
    "print(wav2vec_last.shape,label_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6b50ee-252d-4b2f-b9ea-1253d92075e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.9030, Accuracy: 0.3986\n",
      "########################\n",
      "Accuracy: 0.41659951651893634\n",
      "########################\n",
      "Epoch [2/15], Loss: 0.5135, Accuracy: 0.6904\n",
      "########################\n",
      "Accuracy: 0.48106365834004833\n",
      "########################\n",
      "Epoch [3/15], Loss: 0.4474, Accuracy: 0.7168\n",
      "########################\n",
      "Accuracy: 0.5269943593875906\n",
      "########################\n",
      "Epoch [4/15], Loss: 0.2860, Accuracy: 0.9042\n",
      "########################\n",
      "Accuracy: 0.6518936341659952\n",
      "########################\n",
      "Epoch [5/15], Loss: 0.2201, Accuracy: 0.9828\n",
      "########################\n",
      "Accuracy: 0.6760676873489122\n",
      "########################\n",
      "Epoch [6/15], Loss: 0.1453, Accuracy: 0.9883\n",
      "########################\n",
      "Accuracy: 0.6817082997582594\n",
      "########################\n",
      "Epoch [7/15], Loss: 0.1106, Accuracy: 0.9888\n",
      "########################\n",
      "Accuracy: 0.6881547139403706\n",
      "########################\n",
      "Epoch [8/15], Loss: 0.1054, Accuracy: 0.9888\n",
      "########################\n",
      "Accuracy: 0.6897663174858985\n",
      "########################\n",
      "Epoch [9/15], Loss: 0.0854, Accuracy: 0.9895\n",
      "########################\n",
      "Accuracy: 0.6897663174858985\n",
      "########################\n",
      "Epoch [10/15], Loss: 0.0566, Accuracy: 0.9895\n",
      "########################\n",
      "Accuracy: 0.6905721192586624\n",
      "########################\n",
      "Epoch [11/15], Loss: 0.0746, Accuracy: 0.9895\n",
      "########################\n",
      "Accuracy: 0.6913779210314263\n",
      "########################\n",
      "Epoch [12/15], Loss: 0.0652, Accuracy: 0.9895\n",
      "########################\n",
      "Accuracy: 0.6929895245769541\n",
      "########################\n",
      "Epoch [13/15], Loss: 0.0748, Accuracy: 0.9895\n",
      "########################\n",
      "Accuracy: 0.6962127316680097\n",
      "########################\n",
      "Epoch [14/15], Loss: 0.0440, Accuracy: 0.9900\n",
      "########################\n",
      "Accuracy: 0.6970185334407736\n",
      "########################\n",
      "Epoch [15/15], Loss: 0.0730, Accuracy: 0.9897\n",
      "########################\n",
      "Accuracy: 0.6978243352135375\n",
      "########################\n",
      "Accuracy: 0.6978243352135375\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 256\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = CustomModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "train(model, wav2vec_last, label_last, criterion, optimizer, num_epochs, batch_size)\n",
    "\n",
    "# 测试模型\n",
    "test(model, wav2vec_last5, label_last5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b2fdf-4041-4a76-8979-b81e29a5d16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NeuralCDEenv]",
   "language": "python",
   "name": "neuralcdeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
